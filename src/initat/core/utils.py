# -*- coding: utf-8 -*-

import os
import time
import datetime
import logging_tools
import optparse
import argparse
import process_tools
import smtplib
import xml.dom.minidom
import decimal
import codecs
import random
import csv
import cStringIO
import commands
import email
import email.mime
import email.header
import hashlib
from email.utils import parseaddr, formataddr
from email.mime.text import MIMEText
from lxml import etree
from lxml.builder import E

from openpyxl.writer.excel import save_virtual_workbook
from openpyxl.workbook import Workbook

import django
from django.conf import settings
from django.http import HttpResponse
from django.core.cache import cache
from django.utils.safestring import mark_safe

import reversion


if settings.ZMQ_LOGGING:
    import zmq
else:
    zmq = None

DEBUG_FILE = "/tmp/lp_debug"
TEMP_DIR = "/tmp/xlsx_olim"


def generate_md5_key(*args):
    new_key = hashlib.md5()  # pylint: disable-msg=E1101
    for cur_arg in args:
        new_key.update(unicode(cur_arg))  # pylint: disable-msg=E1101
    return new_key.hexdigest()


class logging_pool(object):
    idle_pool = []
    created = 0
    logger_dict = {}
    if zmq:
        zmq_context = zmq.Context()
    else:
        zmq_context = None

    @staticmethod
    def debug(what):
        if False:  # not settings.IS_WINDOWS:
            if not os.path.isfile(DEBUG_FILE):
                file(DEBUG_FILE, "w").write("%s\n" % (str(datetime.datetime.now())))
                os.chmod(DEBUG_FILE, 0666)
            file(DEBUG_FILE, "a").write("%s\n" % (what))

    @staticmethod
    def get_logger(name="http", **kwargs):
        log_name = "%s.%s" % (settings.REL_SITE_ROOT, name)
        if "init.at.%s" % (log_name) in logging_pool.logger_dict:
            cur_logger = logging_pool.logger_dict["init.at.%s" % (log_name)]
            cur_logger.usecount += 1
            logging_pool.debug("used logger '%s' (usecount is %d, pid is %d)" % (
                log_name,
                cur_logger.usecount,
                os.getpid()))
        else:
            logging_pool.created += 1
            cur_logger = logging_tools.get_logger("%s" % (log_name),
                                                  ["udp:%s" % (kwargs.get("logging_server", "10.240.2.62") or "10.240.2.62")] if settings.IS_WINDOWS else ["uds:/var/lib/logging-server/py_log"],
                                                  init_logger=True,
                                                  zmq=True if zmq else False,
                                                  context=logging_pool.zmq_context)
            cur_logger.log_command("ignore_process_id")
            if "max_file_size" in kwargs:
                cur_logger.log_command("set_file_size %d" % (kwargs["max_file_size"]))
            cur_logger.usecount = 1
            logging_pool.debug("created logger (#%d, pid %d), name '%s'" % (
                logging_pool.created,
                os.getpid(),
                log_name))
            logging_pool.logger_dict[cur_logger.logger.name] = cur_logger
        return cur_logger

    @staticmethod
    def free_logger(cur_logger):
        f_logger_name = cur_logger.logger.name
        logging_pool.logger_dict[f_logger_name].usecount -= 1
        logging_pool.debug("decreased usecount for '%s' to %d (pid %d)" % (
            f_logger_name,
            logging_pool.logger_dict[f_logger_name].usecount,
            os.getpid()
        ))


def call_command(cmd, **kwargs):
    if settings.IS_WINDOWS:
        pipe = os.popen(cmd, "r")
        text = pipe.read()
        sts = pipe.close()
        if sts is None:
            sts = 0
        if text[-1:] == '\n':
            text = text[:-1]
        return sts, text
    else:
        log_cmd = kwargs.get("log_command", None)
        pure_cmd = cmd.split()[0]
        s_time = time.time()
        if not pure_cmd.startswith("/"):
            cmd_found = False
            for s_path in kwargs.get("search_path",
                                     ["/usr/bin", "/bin",
                                      "/usr/sbin", "/sbin",
                                      "/usr/local/bin"]):
                if os.path.isfile("%s/%s" % (s_path, pure_cmd)):
                    cmd = "%s/%s" % (s_path, cmd)
                    cmd_found = True
                    break
        else:
            cmd_found = True
        if cmd_found:
            if "cwd" in kwargs:
                cmd = "cd %s; %s" % (kwargs["cwd"], cmd)
            if log_cmd:
                log_cmd("calling command '%s'%s" % (cmd,
                                                    " (%s)" % (kwargs["info"]) if "info" in kwargs else ""))
            c_stat, c_out = commands.getstatusoutput(cmd)
            e_time = time.time()
            if log_cmd:
                log_cmd(" ... took %s, gave %d (%s)" % (logging_tools.get_diff_time_str(e_time - s_time),
                                                        c_stat,
                                                        logging_tools.get_plural("line", len(c_out.split("\n")))),
                        logging_tools.LOG_LEVEL_WARN if c_stat else logging_tools.LOG_LEVEL_OK)
                if kwargs.get("show_output", False):
                    for l_num, line in enumerate(c_out.split("\n")):
                        log_cmd("   %03d %s" % (l_num + 1, line))
        else:
            if log_cmd:
                log_cmd("command '%s' not found" % (cmd), logging_tools.LOG_LEVEL_ERROR)
            c_stat, c_out = (256, "command not found")
        return c_stat, c_out


def expand_html_body(body_str, **kwargs):
    # remove content-type lines
    new_lines = []
    for line in body_str.split("\n"):
        if line.startswith("<link") and line.count("stylesheet"):
            hr_parts = [part for part in line.split() if part.startswith("href")]
            if hr_parts:
                rel_path = hr_parts[0].split('"')[1]
                if "media_root" in kwargs and "media_path" in kwargs:
                    if kwargs["media_path"].endswith("/") and not kwargs["media_root"].endswith("/"):
                        abs_path = rel_path.replace(kwargs["media_path"], "%s/" % (kwargs["media_root"]))
                    else:
                        abs_path = rel_path.replace(kwargs["media_path"], kwargs["media_root"])
                    if os.path.exists(abs_path):
                        new_lines.append("<style>")
                        new_lines.extend(file(abs_path, "r").read().split("\n"))
                        new_lines.append("</style>")
        else:
            new_lines.append(line)
    if kwargs.get("remove_content_type_line", False):
        if new_lines[0].lower().startswith("content-type"):
            new_lines.pop(0)
    new_text = "\n".join(new_lines)
    return new_text


class progress_counter(object):
    @staticmethod
    def get_counter(**kwargs):
        if "name" in kwargs:
            pc_values = cache.get("pc_%s" % (kwargs["name"]))
            if pc_values:
                return progress_counter(name=kwargs["name"],
                                        max_value=pc_values[0],
                                        act_value=pc_values[1])
            else:
                return None
        else:
            return progress_counter("".join([chr(random.randint(97, 122)) for unused in range(16)]))

    def __init__(self, name, **kwargs):
        self.name = name
        self.max_value = kwargs.get("max_value", 0)
        self.act_value = kwargs.get("act_value", 0)

    def save(self):
        cache.set("pc_%s" % (self.name), [self.max_value, self.act_value])

    def delete(self):
        cache.delete("pc_%s" % (self.name))


class sidebar_element(object):
    def __init__(self, name, **kwargs):
        self.name = unicode(name)
        self.is_folder = kwargs.get("is_folder", False)
        self.node_id = kwargs.get("node_id", None)
        if self.is_folder:
            self.__nodes = []
        self.__args = dict([(key, kwargs[key]) for key in ["isLazy", "url"] if key in kwargs])

    def add_node(self, node):
        if self.is_folder:
            self.__nodes.append(node)

    def get_attribute_string(self):
        attr_list = []
        if self.is_folder:
            attr_list.append("class='folder'")
        if self.node_id:
            attr_list.append("id=\"%s\"" % (self.node_id))
        if self.__args:
            attr_list.append("data=\"%s\"" % (", ".join(["%s: '%s'" % (key, value) for key, value in self.__args.iteritems()])))
        return " ".join(attr_list)

    def get_html(self):
        return mark_safe(u"<li %s>%s%s</li>" % (self.get_attribute_string(),
                                                self.name,
                                                self.get_children("html")))

    def get_json(self):
        ret_dict = {"title": self.name,
                    "isLazy": 1 if self.__args.get("isLazy", False) else 0,
                    "isFolder": 1 if self.is_folder else 0}
        if "url" in self.__args:
            ret_dict["url"] = self.__args["url"]
        return ret_dict

    def get_children(self, mode):
        if self.is_folder and self.__nodes:
            return u"<ul>%s</ul>" % ("".join([getattr(node, "get_%s" % (mode))() for node in self.__nodes]))
        else:
            return ""


def merge_xml(elements):
    if not isinstance(elements, list):
        elements = [elements]
    header = elements[0].split(">", 1)[0]
    # strip xml-header from mother and element
    return "%s><merger>%s</merger>" % (header,
                                       "".join([element.split(">", 1)[1] for element in elements]))


def build_simple_xml_node(master, key, value):
    act_node = master.createElement(key)
    if isinstance(value, (int, long, decimal.Decimal)):
        act_node.setAttribute("type", "int")
        act_node.setAttribute("value", "%d" % (value))
    elif isinstance(value, str):
        act_node.setAttribute("type", "str")
        act_node.setAttribute("value", value)
    elif isinstance(value, bool):
        act_node.setAttribute("type", "bool")
        act_node.setAttribute("value", "1" if value else "0")
    elif isinstance(value, unicode):
        act_node.setAttribute("type", "str")
        act_node.setAttribute("value", value)
    else:
        print "Unknown type %s (%s)" % (type(value), str(value))
    return act_node


def build_simple_xml(head_name, in_dict):
    act_dom = xml.dom.minidom.Document()
    head_info = act_dom.createElement(head_name)
    #head_info.setAttribute("version", "1.0")
    act_dom.appendChild(head_info)
    for key, value in in_dict.iteritems():
        if isinstance(value, list):
            for sub_value in value:
                head_info.appendChild(build_simple_xml_node(act_dom, key, sub_value))
        else:
            head_info.appendChild(build_simple_xml_node(act_dom, key, value))
    return act_dom.toxml("utf-8")


def modify_light(hsv_specs, diff_hue):
    hue, sat, val = hsv_specs
    sat += max(min(diff_hue, 1.0), 0.)
    return (hue, sat, val)


def scale_rgb(rgb_specs, fact, diff):
    ret_val = tuple([min(max(val * fact + diff * val * val / (255 * 255), 0), 255) for val in rgb_specs])
    return ret_val


def hash_cert_number_search(in_str):
    # generate hash for search
    if in_str.count(":"):
        in_str = in_str.split(":", 1)[1]
    return "".join([act_c for act_c in in_str if act_c.isdigit()])


def hash_cert_number(in_str):
    # code from above, sigh...
    map_dict = {u"Ö": "0",
                u"O": "0",
                u"I": "1"}
    s_hash = ""
    for act_c in in_str.upper():
        act_o = ord(act_c)
        if act_c in map_dict:
            new_c = map_dict[act_c]
        elif (act_o < 48) or (act_o > 57 and act_o < 65) or (act_o > 90 and act_o < 97):
            new_c = ""
        elif act_o > 122:
            # warning
            new_c = ""
        else:
            new_c = act_c
        s_hash = u"%s%s" % (s_hash, new_c)
    return s_hash


class unicode_writer(object):
    def __init__(self, func, dialect=csv.excel, encoding="utf-8", **kwds):
        # Redirect output to a queue
        self.queue = cStringIO.StringIO()
        self.writer = csv.writer(self.queue, dialect=dialect, **kwds)
        self.stream = func
        self.encoder = codecs.getincrementalencoder(encoding)()

    def writerow(self, row):
        self.writer.writerow([(s if s is not None else "").encode("utf-8") for s in row])
        # Fetch UTF-8 output from the queue ...
        data = self.queue.getvalue()
        data = data.decode("utf-8")
        # ... and reencode it into the target encoding
        data = self.encoder.encode(data)
        # write to the target stream
        self.stream.write(data)
        # empty queue
        self.queue.truncate(0)

    def writerows(self, rows):
        for row in rows:
            self.writerow(row)


class init_base_object(object):
    """ Provide logging facilities for objects. """
    def __init__(self, name, **kwargs):
        # base object, provides logging facilities
        self.name = name
        if "logger" in kwargs:
            self.__logger = kwargs["logger"]
        else:
            lp_args = {}
            for copy_arg in ["logging_server", "max_file_size"]:
                if copy_arg in kwargs:
                    lp_args[copy_arg] = kwargs[copy_arg]
            self.__logger = logging_pool.get_logger(name, **lp_args)
        self.options = kwargs.get("options", None)
        self._check_options()
        if settings.IS_WINDOWS:
            # write log spacer
            self.log("-" * 50)
        self.__quiet = kwargs.get("quiet", False)
        self._init_step_logging()
        self._log_start()
        self.__mail_lines = []
        self.__mail_lines_log_level = logging_tools.LOG_LEVEL_OK
        self.__step_time = None
        self.__step_num = None
        self.__step_history = None
        self.__act_step = None
        self.__verbose = None

    def mail_log(self, what, log_level=logging_tools.LOG_LEVEL_OK):
        self.log(what, log_level, mail=True)

    def get_logger(self):
        return self.__logger

    def log(self, what, log_level=logging_tools.LOG_LEVEL_OK, **kwargs):
        if self.__verbose:
            print "[%s] %s" % (logging_tools.get_log_level_str(log_level), what)
        self.__logger.log(log_level, what)
        if kwargs.get("mail", False):
            self.__mail_lines.append("[%4s] %s" % (logging_tools.get_log_level_str(log_level), what))
            self.__mail_lines_log_level = max(self.__mail_lines_log_level, log_level)

    def get_mail_lines(self):
        return self.__mail_lines

    def get_mail_lines_log_level(self):
        return self.__mail_lines_log_level

    def _init_step_logging(self):
        self.__act_step, self.__step_num, self.__step_history, self.__step_time = (None, 0, [], None)

    def _get_step_history(self):
        return self.__step_history

    def start_step(self, what=None, *args, **kwargs):
        unknown_kwargs = [key for key in kwargs.iterkeys() if key not in ["mail", "command", "revision"]]
        if unknown_kwargs:
            self.log("unknown keys in kwargs: %s" % (", ".join(unknown_kwargs)),
                     logging_tools.LOG_LEVEL_ERROR,
                     mail=True)
        log_mail = kwargs.get("mail", False)
        with_revison = kwargs.get("revision", False)
        act_time = time.time()
        if self.__act_step:
            # finish
            run_time = act_time - self.__step_time
            self.log("finished step %d (%s) in %s" % (self.__step_num,
                                                      self.__act_step,
                                                      logging_tools.get_diff_time_str(run_time)),
                     mail=log_mail)
            self.__step_history.append((self.__act_step, run_time))
        self.__act_step = what
        self.__step_time = act_time
        if self.__act_step:
            self.__step_num += 1
            self.log("starting step %d: %s" % (self.__step_num,
                                               self.__act_step),
                     mail=log_mail)
            if "command" in kwargs:
                if with_revison:
                    with reversion.revision:
                        getattr(self, kwargs["command"])(*args)
                else:
                    getattr(self, kwargs["command"])(*args)
        else:
            self._step_info(mail=log_mail)

    def get_step_runtime(self, step_name):
        return ([run_time for name, run_time in self.__step_history if name == step_name] + [0])[0]

    def _step_info(self, **kwargs):
        log_mail = kwargs.get("mail", False)
        self.log("executed %s in %s:" % (logging_tools.get_plural("step", len(self.__step_history)),
                                         logging_tools.get_diff_time_str(sum([hist[1] for hist in self.__step_history]))),
                 mail=log_mail)
        for s_idx, (s_name, s_time) in enumerate(self.__step_history):
            self.log("step %d (%-30s) : %s" % (s_idx + 1,
                                               s_name,
                                               logging_tools.get_diff_time_str(s_time)))

    def close(self):
        self.__logger.log(logging_tools.LOG_LEVEL_OK, "CLOSE")

    def _log_start(self):
        if not self.__quiet:
            self.log("starting")
            self.log("options present: %s" % ("yes" if self.options else "no"))
        if self.options:
            if self.__quiet:
                self.log("options:")
            if isinstance(self.options, argparse.Namespace):
                empty_options = argparse.Namespace()
            else:
                empty_options = optparse.Values()
            set_keys = [key for key in dir(self.options) if key not in dir(empty_options)]
            for key in sorted(set_keys):
                value = getattr(self.options, key)
                self.log("%-20s : %-14s is %s" % (key,
                                                  str(type(value)),
                                                  str(getattr(self.options, key))))

    def __del__(self):
        if self.__logger:
            if logging_pool:
                logging_pool.free_logger(self.__logger)
            del self.__logger

    def _check_options(self):
        self.__verbose = False
        if self.options:
            if self.options.verbose:
                self.__verbose = True


class xml_response(object):
    def __init__(self):
        self.reset()

    # pylint: disable-msg=W0201
    def reset(self):
        self.log_buffer = []
        self.val_dict = {}

    def feed_log_line(self, log_level, log_str):
        self.log_buffer.append((log_level, log_str))

    def __setitem__(self, key, value):
        self.val_dict[key] = value

    def __getitem__(self, key):
        return self.val_dict[key]

    def update(self, in_dict):
        for key, value in in_dict.iteritems():
            self[key] = value

    def is_ok(self):
        if self.log_buffer:
            return True if max([log_lev for log_lev, unused in self.log_buffer]) == logging_tools.LOG_LEVEL_OK else False
        else:
            return True

    def build_response(self):
        num_errors, num_warnings = (
            len([True for log_lev, log_str in self.log_buffer if log_lev == logging_tools.LOG_LEVEL_ERROR]),
            len([True for log_lev, log_str in self.log_buffer if log_lev == logging_tools.LOG_LEVEL_WARN]))
        return E.response(
            E.header(
                E.messages(
                    *[E.message(log_str, **{"log_level": "%d" % (log_lev),
                                            "log_level_str": logging_tools.get_log_level_str(log_lev)}) for log_lev, log_str in self.log_buffer]),
                **{"code": "%d" % (max([log_lev for log_lev, log_str in self.log_buffer] + [logging_tools.LOG_LEVEL_OK])),
                   "errors": "%d" % (num_errors),
                   "warnings": "%d" % (num_warnings),
                   "messages": "%d" % (len(self.log_buffer))}),
            E.values(
                *[E.value(value if type(value) == etree._Element else unicode(value), **{
                    "name": key,
                    "type": {
                        int: "integer",
                        long: "integer",
                        str: "string",
                        unicode: "string",
                        float: "float",
                        etree._Element: "xml"}.get(type(value), "unknown")}) for key, value in self.val_dict.iteritems()]
            )
        )

    def __unicode__(self):
        return etree.tostring(self.build_response(), encoding=unicode)

    def create_response(self):
        return HttpResponse(unicode(self),
                            mimetype="application/xml")


def keyword_check(*kwarg_list):
    def decorator(func):
        def _wrapped_view(*args, **kwargs):
            diff_set = set(kwargs.keys()) - set(kwarg_list)
            if diff_set:
                raise KeyError("Invalid keyword arguments: %s" % (str(diff_set)))
            return func(*args, **kwargs)
        return _wrapped_view
    return decorator


def send_emergency_mail(**kwargs):
    # mainly used for windows
    exc_info = process_tools.exception_info()
    if "log_lines" in kwargs:
        mesg = MIMEText("\n".join(kwargs.get("log_lines", [])))
    else:
        mesg = MIMEText("\n".join(exc_info.log_lines))
    mesg["Subject"] = "Python error"
    mesg["From"] = "python-error@init.at"
    mesg["To"] = "oekotex@init.at"
    srv = smtplib.SMTP()
    srv.connect(settings.MAIL_SERVER, 25)
    srv.sendmail(mesg["From"], mesg["To"].split(","), mesg.as_string())
    srv.close()


def create_email(**kwargs):
    body_type = kwargs.get("Body_type", "html")
    header_cs = "utf-8"
    email.charset.add_charset(header_cs, email.charset.QP, email.charset.QP, header_cs)
    if body_type == "text":
        msg_root = email.mime.text.MIMEText(kwargs["Body"], _charset=header_cs)
    else:
        msg_root = email.MIMEMultipart.MIMEMultipart(header_cs)  # pylint: disable-msg=E1101
        msg_root.preamble = "This is a multi-part message in MIME-format."
    if "Subject" in kwargs:
        msg_root["Subject"] = email.header.Header(kwargs["Subject"].encode(header_cs),
                                                  header_cs).encode()
    if "From" in kwargs:
        from_name, from_addr = parseaddr(kwargs["From"])
        msg_root["From"] = formataddr((str(email.header.Header(unicode(from_name), header_cs)), from_addr.encode("ascii")))
    if "To" in kwargs:
        if isinstance(kwargs["To"], list):
            #for to_name, to_addr in [parseaddr(cur_addr) for cur_addr in kwargs["To"]]:
                #msg_root["To"] = formataddr((str(email.header.Header(unicode(to_name), header_cs)), to_addr.encode("ascii")))
            #list with str contains more email_addrs split with , or ; ["addr, addr"]
            for cur_addrs in kwargs["To"]:
                for to_name, to_addr in [parseaddr(cur_addr) for cur_addr in sum([sub_split.split(",") for sub_split in cur_addrs.split(";")], [])]:
                    msg_root["To"] = formataddr((str(email.header.Header(unicode(to_name), header_cs)), to_addr.encode("ascii")))
        elif type(kwargs["To"]) in [type(u""), type("")]:
            for to_name, to_addr in [parseaddr(cur_addr) for cur_addr in sum([sub_split.split(",") for sub_split in kwargs["To"].split(";")], [])]:
                msg_root["To"] = formataddr((str(email.header.Header(unicode(to_name), header_cs)), to_addr.encode("ascii")))
        else:
            raise TypeError("unknown type for To-argument '%s': %s" % (str(kwargs["To"]),
                                                                       type(kwargs["To"])))
    #msg_root.add_header("content-transfer-encoding", "quoted-printable")
    if "Body" in kwargs:
        body_txt = kwargs["Body"]
        if body_type == "html":
            body_txt = expand_html_body(body_txt,
                                        media_path=settings.MEDIA_URL,
                                        media_root=settings.MEDIA_ROOT,
                                        remove_content_type_line=True)
        #for text mails the body is added at the top
        if body_type != "text":
            msg_body = email.MIMEText.MIMEText(body_txt,  # pylint: disable-msg=E1101
                                               body_type,
                                               header_cs)
            msg_root.attach(msg_body)
    return msg_root


def _fix_header(email_obj, h_name):
    c_list = email_obj[h_name]
    del email_obj[h_name]
    if isinstance(c_list, list):
        c_list = ", ".join(c_list)
    email_obj[h_name] = c_list


def _decode_email_field(cur_el, field_name):
    src_val = getattr(cur_el, field_name)
    if src_val.startswith("=?"):
        decoded = email.header.decode_header(src_val.decode("ascii"))
        if decoded[0][0] != src_val:
            setattr(cur_el, field_name, decoded[0][0])


def decode_email_header(cur_el):
    for field_name in ["subject"]:
        _decode_email_field(cur_el, field_name)


class stream_tee(object):
    """Intercept a stream.
    Invoke like so:
    sys.stdout = StreamTee(sys.stdout)
    See: grid 109 for notes on older version (StdoutTee).
    """
    def __init__(self, target):
        self.target = target

    def write(self, out_str):
        self.target.write(self.intercept(out_str))

    def intercept(self, out_str):
        """Pass-through -- Overload this."""
        return out_str


def add_month(in_date, diff):
    next_year, next_month, next_day = (in_date.year,
                                       in_date.month + diff,
                                       in_date.day)
    while next_month > 12:
        next_year += 1
        next_month -= 12
    while next_month < 1:
        next_year -= 1
        next_month += 12
    while True:
        try:
            next_date = in_date.replace(year=next_year,
                                        month=next_month,
                                        day=next_day)
        except Exception:  # pylint: disable-msg=W0703
            next_day -= 1
        else:
            break
    return next_date


def next_bill_date(in_date, interval):
    next_year, next_month = (in_date.year,
                             in_date.month + interval)
    if next_month > 12:
        next_year += 1
        next_month -= 12
    next_date = in_date.replace(year=next_year,
                                month=next_month,
                                day=28)
    while True:
        try:
            next_date = next_date.replace(day=next_date.day + 1)
        except Exception:  # pylint: disable-msg=W0703
            break
    return next_date


class safe_stream_filter(stream_tee):
    # Convert string traffic to to something safe.
    def __init__(self, target):
        stream_tee.__init__(self, target)
        self.encoding = "utf-8"
        self.errors = "replace"
        self.encode_to = "utf-8"

    def intercept(self, out_str):
        return out_str.encode(self.encoding, self.errors)


def mk_last_of_month(dt_datetime):
    d_year = int(dt_datetime.strftime("%Y"))
    d_month = int(int(dt_datetime.strftime("%m")) % 12 + 1)
    d_day = 1
    if d_month == 1:
        d_year += 1
    next_month = datetime.date(d_year, d_month, d_day)
    delta = datetime.timedelta(days=1)
    return next_month - delta


def xlsx_export_response(request, xlsx_dict, name=None):
    from initat.core.alfresco.alfresco import alfresco_handler

    if not name:
        name = "xlsx_export"
    file_name = "%s_export.xlsx" % (name)
    # save_virtual_workbook converts the Workbook-object in a buffer
    # it's heavy time-consuming
    print "save_virtual_workbook, this may take a few minutes..."
    _stime = datetime.datetime.now()
    xlsx_content = save_virtual_workbook(xlsx_dict["xlsx"])
    print "save_virtual_workbook done in %s" % (datetime.datetime.now() - _stime)

    if not os.path.isdir(TEMP_DIR):
        os.mkdir(TEMP_DIR)
    file(os.path.join(TEMP_DIR, file_name), "wb").write(xlsx_content)
    xlsx_file = file(os.path.join(TEMP_DIR, file_name), "rb").read()

    a = alfresco_handler(request.log, directory="Olim")
    testfolder = "test/testfolder"
    print "##", a.get_dir_list(testfolder)
    if a.get_dir_list(testfolder):
        a.store_content("%s/%s" % (testfolder, file_name), xlsx_file, create_new_version_if_exists=True)

        uuid = "WRONG"
        request.xml_response["url"] = django.core.urlresolvers.reverse("xlsx:fetch_content", args=[uuid])
    else:
        request.log()
        a.log("folder \"%s\" not found" % (testfolder), logging_tools.LOG_LEVEL_ERROR)
    return request.xml_response.create_response()


def xlsx_export_create(ammount, col_index="", col_names="", sheetname=None):
    if ammount > 10000000:
        # to many resultx raise Ajax request timeout
        raise OverflowError
    if col_index == "" or col_names == "":
        # we don't want to export all Lucene table fields
        raise ValueError
    wb = Workbook()
    ws = wb.get_active_sheet()
    if sheetname:
        ws.title = sheetname
    col_index = col_index.split(" ")
    col_names = col_names.split(";")
    return {"xlsx": wb, "col_index": col_index, "col_names": col_names}


def xlsx_export_append(xlsx_dict, export_list, start_row=0):
    wb = xlsx_dict["xlsx"]
    ws = wb.get_active_sheet()
    col_index = xlsx_dict["col_index"]
    col_names = xlsx_dict["col_names"]
    r_count = start_row
    if start_row == 0:
        c_count = 0
        for head_col in col_names:
            cell = ws.cell(row=r_count, column=c_count)
            cell.value = head_col
            c_count = c_count + 1
    r_count = r_count + 1
    for raw in export_list:
        c_count = 0
        for field in col_index:
            cell = ws.cell(row=r_count, column=c_count)
            cell_attr = raw
            if isinstance(cell_attr, dict):
                if cell_attr.get(field) is not None:
                    cell.value = cell_attr.get(field)
            else:
                for attr_name in field.replace("__", ".").split("."):
                    cell_attr = getattr(cell_attr, attr_name)
                cell.value = unicode(cell_attr)
            c_count = c_count + 1
        r_count = r_count + 1
    return {"xlsx": wb, "col_index": col_index, "col_names": col_names}
